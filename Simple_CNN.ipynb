{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=[128, 128]\n",
    "EPOCHS = 20\n",
    "# BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration',\n",
       "       'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax', 'Pleural_Thickening',\n",
       "       'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = 'E:/_DOWNLOADED/'\n",
    "img_pth = 'E:/_DOWNLOADED/archive/'\n",
    "\n",
    "train_df_main  = pd.read_csv(os.path.join(pth, 'train_df.csv'))\n",
    "\n",
    "\n",
    "train_df_main .drop(['No Finding'], axis = 1, inplace = True)\n",
    "labels = train_df_main .columns[2:-1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2221     E:/_DOWNLOADED/archive/images_001/images/00000...\n",
       "10626    E:/_DOWNLOADED/archive/images_002/images/00002...\n",
       "93097    E:/_DOWNLOADED/archive/images_010/images/00023...\n",
       "69204    E:/_DOWNLOADED/archive/images_008/images/00017...\n",
       "36126    E:/_DOWNLOADED/archive/images_005/images/00009...\n",
       "80292    E:/_DOWNLOADED/archive/images_009/images/00019...\n",
       "97419    E:/_DOWNLOADED/archive/images_011/images/00025...\n",
       "20590    E:/_DOWNLOADED/archive/images_003/images/00005...\n",
       "48117    E:/_DOWNLOADED/archive/images_006/images/00012...\n",
       "53733    E:/_DOWNLOADED/archive/images_006/images/00013...\n",
       "Name: FilePath, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_main['FilePath'] = train_df_main['FilePath'].str.replace('../input/data','E:/_DOWNLOADED/archive')\n",
    "train_df_main['FilePath'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, discard = train_test_split(train_df_main, test_size = 0.7, random_state = 1993)\n",
    "\n",
    "train_and_valid_set, test_set = train_test_split(train_df, test_size = 0.2, random_state = 1993)\n",
    "train_set, valid_set = train_test_split(train_and_valid_set, test_size = 0.2, random_state = 1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.models import load_model\n",
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "      \n",
    "    print(\"getting train generator...\")\n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization= True, \n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.15,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=True, \n",
    "        vertical_flip = False, \n",
    "        fill_mode = 'reflect')\n",
    "    \n",
    "    \n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=None,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "\n",
    "    print(\"getting train and valid generators...\")\n",
    "    # get generator to sample dataset\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=image_dir, \n",
    "        x_col=\"FilePath\", \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train generator...\n",
      "Found 21526 validated image filenames.\n",
      "getting train and valid generators...\n",
      "Found 21526 validated image filenames.\n",
      "Found 5382 validated image filenames.\n",
      "Found 6728 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_train_generator(df = train_set,\n",
    "                                      image_dir = None, \n",
    "                                      x_col = \"FilePath\",\n",
    "                                      y_cols = labels, \n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      target_w = IMAGE_SIZE[0], \n",
    "                                      target_h = IMAGE_SIZE[1] \n",
    "                                      )\n",
    "\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_df = valid_set, \n",
    "                                                              test_df = test_set, \n",
    "                                                              train_df = train_set,\n",
    "                                                              image_dir = None, \n",
    "                                                              x_col = \"FilePath\", \n",
    "                                                              y_cols = labels,\n",
    "                                                              batch_size = BATCH_SIZE,\n",
    "                                                              target_w = IMAGE_SIZE[0], \n",
    "                                                              target_h = IMAGE_SIZE[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3),padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64,(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 38,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3936320   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                462       \n",
      "=================================================================\n",
      "Total params: 3,977,582\n",
      "Trainable params: 3,977,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "from tensorflow.keras.callbacks import  LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "  1/337 [..............................] - ETA: 0s - loss: 5.3066 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0313s). Check your callbacks.\n",
      "337/337 [==============================] - 442s 1s/step - loss: 5.9609 - accuracy: 0.0338 - val_loss: 5.4236 - val_accuracy: 0.0208\n",
      "Epoch 2/12\n",
      "337/337 [==============================] - 405s 1s/step - loss: 5.8315 - accuracy: 0.0363 - val_loss: 6.6115 - val_accuracy: 0.0208\n",
      "Epoch 3/12\n",
      "337/337 [==============================] - 401s 1s/step - loss: 5.9735 - accuracy: 0.0631 - val_loss: 6.6071 - val_accuracy: 0.0440\n",
      "Epoch 4/12\n",
      "337/337 [==============================] - 404s 1s/step - loss: 6.0220 - accuracy: 0.0544 - val_loss: 5.4206 - val_accuracy: 0.0440\n",
      "Epoch 5/12\n",
      "337/337 [==============================] - 406s 1s/step - loss: 5.7974 - accuracy: 0.0595 - val_loss: 6.6066 - val_accuracy: 0.0440\n",
      "Epoch 6/12\n",
      "337/337 [==============================] - 406s 1s/step - loss: 5.7992 - accuracy: 0.0674 - val_loss: 6.6066 - val_accuracy: 0.0440\n",
      "Epoch 7/12\n",
      "337/337 [==============================] - 391s 1s/step - loss: 5.8290 - accuracy: 0.0604 - val_loss: 5.4236 - val_accuracy: 0.0440\n",
      "Epoch 8/12\n",
      "337/337 [==============================] - 392s 1s/step - loss: 6.0784 - accuracy: 0.0924 - val_loss: 6.8372 - val_accuracy: 0.1394\n",
      "Epoch 9/12\n",
      "337/337 [==============================] - 395s 1s/step - loss: 6.4617 - accuracy: 0.1166 - val_loss: 6.8372 - val_accuracy: 0.1394\n",
      "Epoch 10/12\n",
      "337/337 [==============================] - 412s 1s/step - loss: 6.3176 - accuracy: 0.1176 - val_loss: 6.8372 - val_accuracy: 0.1394\n",
      "Epoch 11/12\n",
      "337/337 [==============================] - 392s 1s/step - loss: 6.4604 - accuracy: 0.1284 - val_loss: 6.8372 - val_accuracy: 0.1394\n",
      "Epoch 12/12\n",
      "337/337 [==============================] - 389s 1s/step - loss: 6.3698 - accuracy: 0.1278 - val_loss: 6.8372 - val_accuracy: 0.1394\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=12,\n",
    "                    callbacks = callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                        patience = 5,\n",
    "                                        \n",
    "                                        mode = 'max'),\n",
    "                    validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, .65])\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 180s - loss: 6.5522 - accuracy: 0.1359\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.13585017621517181  Test loss:  6.552168846130371\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \",test_acc,\" Test loss: \",test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
